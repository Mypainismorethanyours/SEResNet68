{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T23:28:34.686921Z","iopub.status.busy":"2024-04-11T23:28:34.686521Z","iopub.status.idle":"2024-04-11T23:28:41.846694Z","shell.execute_reply":"2024-04-11T23:28:41.845715Z","shell.execute_reply.started":"2024-04-11T23:28:34.686881Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","import torch.optim as optim\n","from torch.optim import Optimizer\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from PIL import Image"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T23:28:41.849017Z","iopub.status.busy":"2024-04-11T23:28:41.848607Z","iopub.status.idle":"2024-04-11T23:28:41.877217Z","shell.execute_reply":"2024-04-11T23:28:41.876164Z","shell.execute_reply.started":"2024-04-11T23:28:41.848990Z"},"trusted":true},"outputs":[],"source":["'''ResNet in PyTorch.\n","\n","For Pre-activation ResNet, see 'preact_resnet.py'.\n","\n","Reference:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","'''\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, conv_kernel_size=3, shortcut_kernel_size=1, drop=0.4):\n","        \"\"\"\n","        Convolutional Layer kernel size Fi \n","        Skip connection (shortcut) kernel size Ki \n","        \"\"\"\n","        super(BasicBlock, self).__init__()\n","        self.drop = drop \n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=conv_kernel_size, stride=stride, padding=int(conv_kernel_size/2), bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=conv_kernel_size,stride=1, padding=int(conv_kernel_size/2), bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,kernel_size=shortcut_kernel_size, stride=stride, padding=int(shortcut_kernel_size/2), bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","        if self.drop: self.dropout = nn.Dropout(self.drop)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        if self.drop: out = self.dropout(out)\n","        return out\n","\n","\n","\n","def conv1x1(in_channels,\n","            out_channels,\n","            stride=1,\n","            groups=1,\n","            bias=False):\n","    \"\"\"\n","    Convolution 1x1 layer.\n","    Parameters:\n","    ----------\n","    in_channels : int\n","        Number of input channels.\n","    out_channels : int\n","        Number of output channels.\n","    stride : int or tuple/list of 2 int, default 1\n","        Strides of the convolution.\n","    groups : int, default 1\n","        Number of groups.\n","    bias : bool, default False\n","        Whether the layer uses a bias vector.\n","    \"\"\"\n","    return nn.Conv2d(\n","        in_channels=in_channels,\n","        out_channels=out_channels,\n","        kernel_size=1,\n","        stride=stride,\n","        groups=groups,\n","        bias=bias)\n","\n","class SEBlock(nn.Module):\n","    \"\"\"\n","    Squeeze-and-Excitation block from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.\n","    Parameters:\n","    ----------\n","    channels : int\n","        Number of channels.\n","    reduction : int, default 16\n","        Squeeze reduction value.\n","    \"\"\"\n","    def __init__(self,\n","                 channels,\n","                 reduction=16):\n","        super(SEBlock, self).__init__()\n","        mid_cannels = channels // reduction\n","\n","        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n","        self.conv1 = conv1x1(\n","            in_channels=channels,\n","            out_channels=mid_cannels,\n","            bias=True)\n","        self.activ = nn.ReLU(inplace=True) \n","\n","        self.conv2 = conv1x1(\n","            in_channels=mid_cannels,\n","            out_channels=channels,\n","            bias=True)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        w = self.pool(x)\n","        w = self.conv1(w)\n","        w = self.activ(w)\n","        w = self.conv2(w)\n","        w = self.sigmoid(w)\n","        x = x * w\n","        return x\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(\n","            self, \n","            block, \n","            num_blocks, \n","            conv_kernel_sizes=None, \n","            shortcut_kernel_sizes=None,\n","            num_classes=10, \n","            num_channels=32, \n","            avg_pool_kernel_size=4, \n","            drop=None, \n","            squeeze_and_excitation=None):\n","        super(ResNet, self).__init__()\n","        self.in_planes = num_channels\n","        # self.avg_pool_kernel_size = avg_pool_kernel_size \n","        self.avg_pool_kernel_size = int(32 / (2**(len(num_blocks)-1)))\n","        \n","        \"\"\"\n","        # of channels Ci \n","        \"\"\"\n","        self.num_channels = num_channels\n","        self.conv1 = nn.Conv2d(3, self.num_channels, kernel_size=3,stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(self.num_channels) \n","\n","        self.drop = drop \n","        self.squeeze_and_excitation = squeeze_and_excitation \n","\n","        if self.squeeze_and_excitation: \n","            self.seblock = SEBlock(channels=self.num_channels) \n","\n","        \"\"\"\n","        # of Residual Layers N \n","        # of Residual Blocks Bi \n","        \"\"\"\n","        self.residual_layers = [] \n","        for n in range(len(num_blocks)): \n","            stride = 1 if n==0 else 2 # stride=1 for first residual layer, and stride=2 for the remaining layers \n","            conv_kernel_size = conv_kernel_sizes[n] if conv_kernel_sizes else 3 # setting default kernel size of block's convolutional layers \n","            shortcut_kernel_size = shortcut_kernel_sizes[n] if shortcut_kernel_sizes else 1 # setting default kernel size of block's skip connection (shortcut) layers \n","            self.residual_layers.append(self._make_layer(\n","                                                    block, \n","                                                    self.num_channels*(2**n), \n","                                                    num_blocks[n], \n","                                                    stride=stride, \n","                                                    conv_kernel_size=conv_kernel_size, \n","                                                    shortcut_kernel_size=shortcut_kernel_size)) \n","\n","        self.residual_layers = nn.ModuleList(self.residual_layers)\n","        self.linear = nn.Linear(self.num_channels*(2**n)*block.expansion, num_classes) \n","        \"\"\"\n","        Dropout layer \n","        \"\"\"\n","        if self.drop: \n","            self.dropout = nn.Dropout(self.drop) # Define proportion or neurons to dropout\n","\n","    def _make_layer(self, block, planes, num_blocks, stride, conv_kernel_size, shortcut_kernel_size):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride, conv_kernel_size, shortcut_kernel_size, drop=self.drop))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        if self.squeeze_and_excitation: out = self.seblock(out) \n","        for layer in self.residual_layers: \n","            out = layer(out)         \n","        \"\"\"\n","        Average pool kernel size \n","        \"\"\"\n","        out = F.avg_pool2d(out, self.avg_pool_kernel_size)\n","        out = out.view(out.size(0), -1)\n","        if self.drop: out = self.dropout(out)\n","        out = self.linear(out)\n","        return out"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T23:29:01.573393Z","iopub.status.busy":"2024-04-11T23:29:01.573037Z","iopub.status.idle":"2024-04-11T23:29:40.316550Z","shell.execute_reply":"2024-04-11T23:29:40.315606Z","shell.execute_reply.started":"2024-04-11T23:29:01.573364Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID  Labels\n","0   0       8\n","1   1       8\n","2   2       8\n","3   3       8\n","4   4       8"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pickle\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import numpy as np\n","from PIL import Image\n","\n","class CustomCIFAR10Dataset(Dataset):\n","    def __init__(self, file_path, transform=None):\n","        with open(file_path, 'rb') as f:\n","            data = pickle.load(f)\n","            self.images = data[b'data']\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        image = image.reshape(3, 32, 32).transpose((1, 2, 0)) \n","        image = Image.fromarray(image)\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        return image\n","    \n","def compute_mean_std(dataset):\n","    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n","    \n","    mean = torch.zeros(3)\n","    std = torch.zeros(3)\n","    total_images = 0\n","    \n","    for images in dataloader:\n","        # batch_size, height, width, channels\n","        batch_samples = images.size(0)\n","        images = images.view(batch_samples, images.size(1), -1)\n","        mean += images.mean(2).sum(0)\n","        std += images.var(2).sum(0)\n","        total_images += batch_samples\n","        \n","    mean /= total_images\n","    std = torch.sqrt(std / total_images)\n","    return mean, std\n","\n","custom_test_dataset = CustomCIFAR10Dataset(file_path='./cifar_test_nolabels.pkl', transform=transforms.ToTensor())\n","mean, std = compute_mean_std(custom_test_dataset)\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4913996458053589, 0.48215845227241516, 0.44653093814849854), (0.2470322549343109, 0.24348513782024384, 0.26158788800239563))\n","#     transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n","])\n","custom_test_dataset = CustomCIFAR10Dataset(file_path='./cifar_test_nolabels.pkl', transform=transform)\n","test_loader = DataLoader(custom_test_dataset, batch_size=1, shuffle=False)\n","\n","net = ResNet(\n","    block=BasicBlock, \n","    num_blocks=[4, 4, 3],                   # N: number of Residual Layers | Bi:Residual blocks in Residual Layer i \n","    conv_kernel_sizes=[3, 3, 3],            # Fi: Conv. kernel size in Residual Layer i \n","    shortcut_kernel_sizes=[1, 1, 1] ,       # Ki: Skip connection kernel size in Residual Layer i \n","    num_channels=64,                        # Ci: # channels in Residual Layer i \n","    avg_pool_kernel_size=8,                 # P: Average pool kernel size \n","    drop=0,                                 # use dropout with drop proportion \n","    squeeze_and_excitation=1                # Enable/disable Squeeze-and-Excitation Block \n","    ) \n","\n","checkpoint = torch.load('./best_acc_model/best.pth')\n","net.load_state_dict(checkpoint['net'])\n","\n","predicted_label = []\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","net = net.to(device)\n","net.eval()\n","\n","with torch.no_grad():\n","    for batch_idx, inputs in enumerate(test_loader):\n","        inputs = inputs.to(device)\n","        outputs = net(inputs)\n","        _, predicted = outputs.max(1)\n","        predicted_label.append(predicted.cpu().numpy())\n","        \n","submission = pd.DataFrame(predicted_label, columns=['Labels'])\n","submission.insert(0, 'ID', range(0, len(submission)))\n","submission.to_csv('./submission.csv', index=False)\n","submission.head()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8112053,"sourceId":73233,"sourceType":"competition"},{"datasetId":4746361,"sourceId":8048813,"sourceType":"datasetVersion"},{"datasetId":4746597,"sourceId":8049162,"sourceType":"datasetVersion"},{"datasetId":4753056,"sourceId":8058290,"sourceType":"datasetVersion"},{"datasetId":4767192,"sourceId":8077613,"sourceType":"datasetVersion"},{"datasetId":4772208,"sourceId":8084526,"sourceType":"datasetVersion"},{"datasetId":4774184,"sourceId":8087451,"sourceType":"datasetVersion"},{"datasetId":4779288,"sourceId":8094702,"sourceType":"datasetVersion"},{"datasetId":4780623,"sourceId":8096584,"sourceType":"datasetVersion"},{"datasetId":4785980,"sourceId":8103739,"sourceType":"datasetVersion"},{"datasetId":4785990,"sourceId":8103750,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
